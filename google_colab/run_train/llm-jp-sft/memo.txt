環境を作成
conda create -n sft python=3.11 -y
conda activate sft

cd document/sftlab
pip install -r requirements.in 

export LD_LIBRARY_PATH={path/to/your/miniconda3}/envs/sft/lib/python3.11/site-packages/nvidia/nvjitlink/lib:$LD_LIBRARY_PATH
export LD_LIBRARY_PATH={path/to/your/anaconda3}/envs/sft/lib/python3.11/site-packages/nvidia/nvjitlink/lib:$LD_LIBRARY_PATH

pip install flash-attn --no-build-isolation
pip install --upgrade accelerate
pip install datasets


環境を起動
conda activate sft

環境を終了
conda deactivate

実行コマンド
cd docu/ment/sftlabexperiments/test_project


lora_sft_コマンド
python run.py tanuki8b_lora_001.yaml


full_sft_コマンド
python run.py train_full_sft.yaml
python run.py train_full_sft_cos.yaml



推論プログラム
python src_inference/inference_chat.py
python src_inference/inference_text.py

python src_inference/inference_text_instruct2.py


python train.py \
    --num_train_epochs 1 \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 4 \
    --gradient_accumulation_steps 8 \
    --learning_rate 1e-5 \
    --warmup_ratio 0.1 \
    --lr_scheduler_type cosine \
    --bf16 \
    --max_seq_length 4096 \
    --data_files ../data/example.jsonl \
    --model_name_or_path ../model/puwaer-1.8b_45 \
    --output_dir results/


python train_chat.py \
    --num_train_epochs 1 \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 4 \
    --gradient_accumulation_steps 8 \
    --learning_rate 5e-5 \
    --warmup_ratio 0.1 \
    --lr_scheduler_type cosine \
    --bf16 \
    --data_files ./data/text_1-1000_sft_1_1.jsonl \
    --model_name_or_path ./model/puwaer-1.8b_45 \
    --output_dir results/doujinshi-1.8b-instruct-1/ \
    --wandb_project "puwaer-sft" \
    --wandb_run_name "doujinshi-1.8b-instruct-1" \
    --wandb_log_steps 10